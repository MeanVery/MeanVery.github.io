<!DOCTYPE html>













<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  
  <title>Seminar-20221017-BERT, ViT - Very的计算机学习</title>

  
  
  <meta name="description" content="感谢白宇师兄的讲解！
BERT12 Bert和GPT,ELMo 对比示意图​	BERT 可以真正结合上下文信息，而不想 GPT 那样只能接收上文信息，同时采用了“Masked Language Model”随机屏蔽一些单词，以这个作为预训练目标，缓解单向语言模型的约束。
​	BERT 和之前的模型类似之处在于都采用了两个阶段，首先是 pre-training，然后是 fine-tuning。在 pre-training 阶段，BERT 在没有标注的数据上进行无监督学习，在 fine-tuning 阶段，BERT 首先利用预训练得到的参数初始化模型，然后利用下游任务中，标记好的模型进行带监督的学习，并对所有的参数进行微调。
​	为了能够处理各种任务，BERT 给出了句子级别的表示方案，包括单个句子和句子对，同时在 BERT 中，句子实际上指的是任意长度的连续文本，而不是语法意义上的某个句子。
​	BERT 的编码采用的是 WordPiece。每个序列的开头都是一个特殊的类别标记 CLS。区分句子对中前后两句的方法：首先是用特殊的分隔符标记 SEP 把不同的句子隔开，然后在每个标记中加入一个学习得到的编码，以此来显示该标记是属于句子队中的句子 A 还是句子 B。
​	最终一个标记的表示其实是由 3 个部分组成，1 是标记本身的含义编码，2 是显示属于哪个句子的编码，3 是学习得到的位置编码，如下图：
BERT 输入编码示意图​	​	BERT 采用了两种非监督任务来进行预训练，一个是 token-level 级别的屏蔽模型（Masked LM），一个是 sentence level 级别的 Next Sentence Prediction。BERT 的损失函数也是两个任务的损失函数之和。
Masked Language Model ( MLM )
其实在类似完型填空的任务中，如果直接使用双向语言模型，那么模型就可以间接知道要预测的单词，所以为了解决这个问题，谷歌提出了 Masked LM，随机屏蔽一些 token，并通过上下文预测这些 token。在具体的实验中，BERT 会随机屏蔽每个序列中 15% 的 token 并用 mask token 来代替。但是真实的任务中以及在进行参数的微调时，没有 mask token，所以为了缓解 mask 的影响，谷歌的方法是：选中 15% 的标记，准备进行 mask，在这 15% 当中，选择 80% 直接 mask 掉， 选择 10% 赋予随机的标记，最后 10% 保持原来的标记不变。然后这 15% 的位置将在交叉熵损失函数的控制下，来用于预测原本的值。" />
  <meta name="author" content="MeanVery" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://meanvery.github.io/app.min.css" />

  
  <link rel="preload stylesheet" as="style" href="https://meanvery.github.io/an-old-hope.min.css" />
  <script
    defer
    src="https://meanvery.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  <link rel="preload" as="image" href="https://meanvery.github.io/theme.png" />

  
  <link rel="preload" as="image" href="https://meanvery.github.io/github.svg" />
  

  
  <link rel="icon" href="https://meanvery.github.io/favicon.ico" />
  <link rel="apple-touch-icon" href="https://meanvery.github.io/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.101.0" />

  
  

  
  
  
  
  
  
  
  
  
  <meta property="og:title" content="Seminar-20221017-BERT, ViT" />
<meta property="og:description" content="Seminar about BERT, ViT" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://meanvery.github.io/post/seminar-20221021/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-10-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-10-24T00:00:00+00:00" />


  
  <meta itemprop="name" content="Seminar-20221017-BERT, ViT">
<meta itemprop="description" content="Seminar about BERT, ViT"><meta itemprop="datePublished" content="2022-10-24T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-10-24T00:00:00+00:00" />
<meta itemprop="wordCount" content="162">
<meta itemprop="keywords" content="" />
  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Seminar-20221017-BERT, ViT"/>
<meta name="twitter:description" content="Seminar about BERT, ViT"/>

  
  
</head>


  <body class="not-ready" data-menu="true">
    <header class="header">
  
  <p class="logo">
    <a class="site-name" href="https://meanvery.github.io/">Very的计算机学习</a><a class="btn-dark"></a>
  </p>
  

  <script>
    let bodyClx = document.body.classList;
    let btnDark = document.querySelector('.btn-dark');
    let sysDark = window.matchMedia('(prefers-color-scheme: dark)');
    let darkVal = localStorage.getItem('dark');

    let setDark = (isDark) => {
      bodyClx[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark ? 'yes' : 'no');
    };

    setDark(darkVal ? darkVal === 'yes' : sysDark.matches);
    requestAnimationFrame(() => bodyClx.remove('not-ready'));

    btnDark.addEventListener('click', () => setDark(!bodyClx.contains('dark')));
    sysDark.addEventListener('change', (event) => setDark(event.matches));
  </script>

  
  
  <nav class="menu">
    
    <a class="" href="/about/">关于</a>
    
  </nav>
  

  
  <nav class="social">
    
    <a
      class="github"
      style="--url: url(./github.svg)"
      href="https://github.com/MeanVery"
      target="_blank"
    ></a>
    
  </nav>
  
</header>


    <main class="main">

<article class="post-single">
  <header class="post-title">
    <p>
      
      <time>Oct 24, 2022</time>
      
      
      <span>MeanVery</span>
      
    </p>
    <h1>Seminar-20221017-BERT, ViT</h1>
  </header>
  <section class="post-content">

<!-- KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



<p>感谢白宇师兄的讲解！</p>
<h2 id="bert1cite2cite">BERT<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></cite><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></cite></h2>
<div>
    <center>
    <img src="/bert1.png"
         alt="Bert和GPT,ELMo 对比示意图"
         style="zoom:50%"/>
    Bert和GPT,ELMo 对比示意图
    </center>
</div>
<br>
<p>​	BERT 可以真正结合上下文信息，而不想 GPT 那样只能接收上文信息，同时采用了“Masked Language Model”随机屏蔽一些单词，以这个作为预训练目标，缓解单向语言模型的约束。</p>
<p>​	BERT 和之前的模型类似之处在于都采用了两个阶段，首先是 pre-training，然后是 fine-tuning。在 pre-training 阶段，BERT 在没有标注的数据上进行无监督学习，在 fine-tuning 阶段，BERT 首先利用预训练得到的参数初始化模型，然后利用下游任务中，标记好的模型进行带监督的学习，并对所有的参数进行微调。</p>
<p>​	为了能够处理各种任务，BERT 给出了句子级别的表示方案，包括单个句子和句子对，同时在 BERT 中，句子实际上指的是任意长度的连续文本，而不是语法意义上的某个句子。</p>
<p>​	BERT 的编码采用的是 WordPiece。每个序列的开头都是一个特殊的类别标记 CLS。区分句子对中前后两句的方法：首先是用特殊的分隔符标记 SEP 把不同的句子隔开，然后在每个标记中加入一个学习得到的编码，以此来显示该标记是属于句子队中的句子 A 还是句子 B。</p>
<p>​	最终一个标记的表示其实是由 3 个部分组成，1 是标记本身的含义编码，2 是显示属于哪个句子的编码，3 是学习得到的位置编码，如下图：</p>
<div>
    <center>
    <img src="/bert2.png"
         alt="BERT 输入编码示意图"
         style="zoom:50%"/>
    BERT 输入编码示意图
    </center>
</div>
<p>​	<br></p>
<p>​	BERT 采用了两种非监督任务来进行预训练，一个是 token-level 级别的屏蔽模型（Masked LM），一个是 sentence level 级别的 Next Sentence Prediction。BERT 的损失函数也是两个任务的损失函数之和。</p>
<ul>
<li>
<p>Masked Language Model ( MLM )</p>
<p>其实在类似完型填空的任务中，如果直接使用双向语言模型，那么模型就可以间接知道要预测的单词，所以为了解决这个问题，谷歌提出了 Masked LM，随机屏蔽一些 token，并通过上下文预测这些 token。在具体的实验中，BERT 会随机屏蔽每个序列中 15% 的 token 并用 mask token 来代替。但是真实的任务中以及在进行参数的微调时，没有 mask token，所以为了缓解 mask 的影响，谷歌的方法是：选中 15% 的标记，准备进行 mask，在这 15% 当中，选择 80% 直接 mask 掉， 选择 10% 赋予随机的标记，最后 10% 保持原来的标记不变。然后这 15% 的位置将在交叉熵损失函数的控制下，来用于预测原本的值。</p>
</li>
<li>
<p>Next Sentence Prediction ( NSP )</p>
</li>
</ul>
<p>​</p>
<p>​	在 fine-tuning 阶段，只需要将具体的输入和输出适配到 Bert 中，并且用端到端的训练去微调模型的参数，就可以适用于各种任务，实际只需要在核心模型中添加类似分类层的层次即可。</p>
<h2 id="vit3cite4cite5cite">ViT<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></cite><sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></cite><sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></cite></h2>
<p>Vision Transformer (ViT) 最核心的结论是，当拥有足够多的数据进行预训练的时候，ViT 的表现就会超过 CNN，突破 transformer 缺少归纳偏置的限制，可以在下游任务中获得较好的迁移效果。</p>
<p>​	但是当训练数据集不够大的时候，ViT 的表现通常比同等大小的 ResNets 要差一些，因为 Transformer 和 CNN 相比缺少归纳偏置，即一种先验知识，提前做好的假设。</p>
<div>
    <center>
    <img src="/vit1.png"
         alt="Vision Transformer 示意图"
         style="zoom:50%"/>
    Vision Transformer 示意图
    </center>
</div>
<br>
<p>​	在整体的实现上，本文出发点是彻底抛弃 CNN，以前的 CV 领域虽然引入 Transformer，但是或多或少都用到了 CNN 或者 RNN，原始直接使用纯 Transformer 的结构并且取得了不错的结果。原文完全使用原始 Bert 的 Transformer 结构，主要是对图片转换成类似 token 的处理，原文引入了一个 patch 的概念，即将输入图片划分为一个个的 patch，然后对于每一个 patch 转换（主要是flatten操作），转换成类似 Bert 的输入结构。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://arxiv.org/pdf/1810.04805.pdf">https://arxiv.org/pdf/1810.04805.pdf</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://blog.csdn.net/u013602059/article/details/107085999">https://blog.csdn.net/u013602059/article/details/107085999</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://arxiv.org/pdf/2010.11929.pdf">https://arxiv.org/pdf/2010.11929.pdf</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://zhuanlan.zhihu.com/p/445122996">https://zhuanlan.zhihu.com/p/445122996</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="https://zhuanlan.zhihu.com/p/355541661">https://zhuanlan.zhihu.com/p/355541661</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
</section>

  
  

  
  
  
  <nav class="post-nav">
     
    <a class="next" href="https://meanvery.github.io/post/seminar-20221010/"><span>Seminar-20221010-Self Attention, Transformer</span><span>→</span></a>
    
  </nav>
  

  
  
</article>

</main>

    <footer class="footer">
  <p>&copy; 2022 <a href="https://meanvery.github.io/">Very的计算机学习</a></p>
  <p>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</p>
  <p>
    <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper 5.1</a>
  </p>
</footer>

  </body>
</html>
