<!DOCTYPE html>













<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />

  
  <title>Seminar-20220820 - Very的计算机学习</title>

  
  
  <meta name="description" content="感谢高丹阳学姐的讲解！## AlexNet#### * 首次使用GPU进行模型训练* 使用ReLU激活函数代替Sigmoid/Tanh* 使用规范层(Local Response Normalization, LRN)* 使用随机丢弃策略(Dropout)## GoogLeNet[^1][^2]Inception(也称为GoogLeNet)结构的核心思想与贡献：#### - 使用 \(1\times1\) 的卷积来进行升降维- 在相同尺寸的感受野种叠加更多的卷积，能提取更丰富的特征。同时在卷积之后都跟着激活函数，多层卷积与激活也有助于组合出更多的非线性特征- 降低了计算的复杂度，对输入降维后再做卷积计算量明显减小* 在多个尺寸上同时进行卷积后再进行聚合* 直观上在多个尺度上同时进行卷积，能提取到不同尺度的特征，特征更丰富也意味着最后分类判断时更加准确* 利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度* Hebbin赫布原理，&#34;fire together, wire together&#34; : 两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种组合，其中一个神经元的兴奋会促进另一个的兴奋GoogLeNet网络深度深，为了避免梯度消失，网络额外增加了两个辅助的Softmax用于向前传导梯度。## VGGNet[^3]采用连续的几个 \(3\times3\) 卷积核代替AlexNet中的较大卷积核，即&#34;金字塔方法&#34;。金字塔方法示意图#### - 优点- 结构简洁，整个网络都使用了相同大小的卷积核尺寸( \(3\times3\) )和最大池化尺寸(\(2\times2\))- 几个小卷积核的组合比一个大卷积核效果更好- 验证了加深网络结构可以提升性能* 缺点* 是同了更多参数，耗费更多计算资源，导致更多的内存占用" />
  <meta name="author" content="MeanVery" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://meanvery.github.io/app.min.css" />

  
  <link rel="preload stylesheet" as="style" href="https://meanvery.github.io/an-old-hope.min.css" />
  <script
    defer
    src="https://meanvery.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  <link rel="preload" as="image" href="https://meanvery.github.io/theme.png" />

  
  <link rel="preload" as="image" href="https://meanvery.github.io/github.svg" />
  

  
  <link rel="icon" href="https://meanvery.github.io/favicon.ico" />
  <link rel="apple-touch-icon" href="https://meanvery.github.io/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.101.0" />

  
  

  
  
  
  
  
  
  
  
  
  <meta property="og:title" content="Seminar-20220820" />
<meta property="og:description" content="Seminar about &#34;AlexNet&#34; , &#34;GoogLeNet&#34; , &#34;VGGNet&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://meanvery.github.io/post/seminar-20220820/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-08-22T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-08-22T00:00:00+00:00" />


  
  <meta itemprop="name" content="Seminar-20220820">
<meta itemprop="description" content="Seminar about &#34;AlexNet&#34; , &#34;GoogLeNet&#34; , &#34;VGGNet&#34;"><meta itemprop="datePublished" content="2022-08-22T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-08-22T00:00:00+00:00" />
<meta itemprop="wordCount" content="62">
<meta itemprop="keywords" content="" />
  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Seminar-20220820"/>
<meta name="twitter:description" content="Seminar about &#34;AlexNet&#34; , &#34;GoogLeNet&#34; , &#34;VGGNet&#34;"/>

  
  
</head>


  <body class="not-ready" data-menu="true">
    <header class="header">
  
  <p class="logo">
    <a class="site-name" href="https://meanvery.github.io/">Very的计算机学习</a><a class="btn-dark"></a>
  </p>
  

  <script>
    let bodyClx = document.body.classList;
    let btnDark = document.querySelector('.btn-dark');
    let sysDark = window.matchMedia('(prefers-color-scheme: dark)');
    let darkVal = localStorage.getItem('dark');

    let setDark = (isDark) => {
      bodyClx[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark ? 'yes' : 'no');
    };

    setDark(darkVal ? darkVal === 'yes' : sysDark.matches);
    requestAnimationFrame(() => bodyClx.remove('not-ready'));

    btnDark.addEventListener('click', () => setDark(!bodyClx.contains('dark')));
    sysDark.addEventListener('change', (event) => setDark(event.matches));
  </script>

  
  
  <nav class="menu">
    
    <a class="" href="/about/">关于</a>
    
  </nav>
  

  
  <nav class="social">
    
    <a
      class="github"
      style="--url: url(./github.svg)"
      href="https://github.com/MeanVery"
      target="_blank"
    ></a>
    
  </nav>
  
</header>


    <main class="main">

<article class="post-single">
  <header class="post-title">
    <p>
      
      <time>Aug 22, 2022</time>
      
      
      <span>MeanVery</span>
      
    </p>
    <h1>Seminar-20220820</h1>
  </header>
  <section class="post-content">

<!-- KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>







感谢高丹阳学姐的讲解！

## AlexNet

#### 

* 首次使用GPU进行模型训练
* 使用ReLU激活函数代替Sigmoid/Tanh
* 使用规范层(Local Response Normalization, LRN)
* 使用随机丢弃策略(Dropout)

## GoogLeNet[^1]</cite>[^2]</cite>

Inception(也称为GoogLeNet)结构的核心思想与贡献：

#### 

- 使用 \(1\times1\) 的卷积来进行升降维
  - 在相同尺寸的感受野种叠加更多的卷积，能提取更丰富的特征。同时在卷积之后都跟着激活函数，多层卷积与激活也有助于组合出更多的非线性特征
  - 降低了计算的复杂度，对输入降维后再做卷积计算量明显减小

* 在多个尺寸上同时进行卷积后再进行聚合
  * 直观上在多个尺度上同时进行卷积，能提取到不同尺度的特征，特征更丰富也意味着最后分类判断时更加准确
  * 利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度
  * Hebbin赫布原理，"fire together, wire together" : 两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种组合，其中一个神经元的兴奋会促进另一个的兴奋

GoogLeNet网络深度深，为了避免梯度消失，网络额外增加了两个辅助的Softmax用于向前传导梯度。

## VGGNet[^3]</cite>

采用连续的几个 \(3\times3\) 卷积核代替AlexNet中的较大卷积核，即"金字塔方法"。

<div>
    <center>
    <img src="/jinzita.png"
         alt="金字塔方法示意图"
         style="zoom:50%"/>
    金字塔方法示意图
    </center>
</div>

#### 

- 优点
  - 结构简洁，整个网络都使用了相同大小的卷积核尺寸( \(3\times3\) )和最大池化尺寸(\(2\times2\))
  - 几个小卷积核的组合比一个大卷积核效果更好
  - 验证了加深网络结构可以提升性能

* 缺点
  * 是同了更多参数，耗费更多计算资源，导致更多的内存占用


</section>

  
  

  
  
  
  <nav class="post-nav">
    
    <a class="prev" href="https://meanvery.github.io/post/typora/"><span>←</span><span>Typora</span></a>
     
    <a class="next" href="https://meanvery.github.io/post/20220711/"><span>An Overview of Computer Vision</span><span>→</span></a>
    
  </nav>
  

  
  
</article>

</main>

    <footer class="footer">
  <p>&copy; 2022 <a href="https://meanvery.github.io/">Very的计算机学习</a></p>
  <p>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</p>
  <p>
    <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper 5.1</a>
  </p>
</footer>

  </body>
</html>
