<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Very的计算机学习</title>
    <link>https://meanvery.github.io/post/</link>
    <description>Recent content in Posts on Very的计算机学习</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright © 2008–2019, Steve Francia and the lee.so; all rights reserved.</copyright>
    <lastBuildDate>Sat, 27 Aug 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meanvery.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Seminar-20220827-SENet, MobileNet</title>
      <link>https://meanvery.github.io/post/seminar-20220827/</link>
      <pubDate>Sat, 27 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220827/</guid>
      <description>感谢张若淇师兄的讲解！
SENet1 2 3 ​	在之前的研究中，人们重点关注空间维度上特征的联系与交互，但是 SENet 研究了网络设计的不同方面——通道（channel）之间的关系。SENet 设计了一个新的结构单元，称之为 Squeeze-and-Excitation（SE）块，它是为了建立特征图通道之间的关系，并以此来提升特征表示的效果。
A Squeeze-and-Excitation block​	其中， \(X\) 是初始的特征图，高度宽度通道数分别为 \(H&#39;\) ， \(W&#39;\) ， \(C&#39;\) 。
​	\(F_{tr}\) 是传统的卷积操作将 \(X\) 变换为 \(U\) ，高度宽度通道数分别为 \(H\) ， \(W\) ， \(C\) 。
​	然后使 \(U\) 经过 Squeeze 操作即 \(F_{sq}\) ，变换成 \(1 \times 1 \times C\) 的通道描述向量 \(z\) 。实际上是用全局平均池化，将每一通道上原本为 \(H \times W\) 的二维矩阵通过求平均的方式，化为一个实数，这个实数其实一定程度上包含了每一通道上的全局视野。同时，化成 \(1 \times 1 \times C\) 也避免了高度和宽度（也即空间特征）带来的影响，从而突出了通道的作用。
​	再让 \(1 \times 1 \times C\) 的通道描述向量 \(z\) 经过 Excitation 变换，实际上经过了两个全连接层。</description>
    </item>
    
    <item>
      <title>Seminar-20220824-ResNet, DenseNet</title>
      <link>https://meanvery.github.io/post/seminar-20220824/</link>
      <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220824/</guid>
      <description>感谢陈露元同学的讲解！
ResNet1 2 ​	从之前已有的研究中可以看出，似乎神经网络的深度越深，学习效果就越好。但这个结论其实并不可靠：一个问题是，随着深度的增加而出现的梯度消失或梯度爆炸现象，影响最后的收敛，不过这种收敛问题可以通过正则化（regularization）得到部分解决；另一个问题是，网络即使收敛，在深度增加时，正确率却无法进一步提高甚至还会下降，称为网络的退化（degradation）问题。
​	考虑一个极端的情形，如果增加的所有层都是前一层的直接复制，那么深层网络的训练误差应当和浅层网络相等，因此网络退化的根本原因是优化的问题，不是所有的系统都很容易优化。
​	为了解决优化的难题，提出了残差网络，不让网络直接拟合原先的映射，而是拟合残差映射。
Residual learning: a building block​	上图为残差网络中的一个模块，identity mapping 为恒等映射。由上图，残差网络可以理解为在前向网络中增加了一些快捷连接（shortcut connections），这些连接会跳过某些层，直接将原始数据传到之后的层。新增的快捷连接也不会增加模型的参数和复杂度，整个模型依然可以使用端到端的方法进行训练（比如随机梯度下降法）。
不同层数的ResNet架构总结 ​	ResNet 将部分原始输入信息不经过矩阵乘法和非线性变换，直接传输到下一层，快捷连接如同在深层网络中建立起了信息的捷径。通过改变学习目标，残差网络不再学习完整的输出而是学习残差，不仅降低了学习的难度，而且解决了传统卷积层或者全连接层在信息传递时存在的丢失和损耗问题——直接将信息从输入绕道传到输出，一定程度上保护了信息的完整性。
ResNet.version23 4 对resnet的改良​	实验表明，保持一个单纯的信息传送通道（如上图中 b 所示）对降低优化的难度有帮助。
残差网络的分析
原始版本的残差模块，利用公式描述如下： $$ y_l = h(x_l)+F(x_l,W_l)&amp;hellip;(1) $$
$$ x_{l+1} = f(y_l)&amp;hellip;(2) $$
其中，\(x_l\)为第\(l\)层残差模块的输入特征，\(W_l\)是权重系数，\(F\)是残差函数，\(f\)是ReLU函数，\(h\)是恒等映射，即\(h({x_l}) = x_l\)。
如果我们设\(f\)也是恒等映射，即\(x_{l+1} = y_l\)，则可将（2）式代入（1）式，可得： $$ x_{l+1} = x_l + F(x_l,W_l)&amp;hellip;(3) $$ 类似的可推得： $$ x_L= x_l + \displaystyle\sum_{i=l}^{L-1}F(x_i,W_i)&amp;hellip;(4) $$ 由（4）式可得任意深层特征都可以用浅层特征加上残差项来表达，而对原始 ResNet，深层特征实际是各项相乘。
对损失函数求导可得： $$ \dfrac{\partial \varepsilon}{\partial x_l}=\dfrac{\partial \varepsilon}{\partial x_L}\dfrac{\partial x_L}{\partial x_l}=\dfrac{\partial \varepsilon}{\partial x_L}\Big(1+\dfrac{\partial}{\partial x_l}\displaystyle\sum_{i=l}^{L-1}F(x_i,W_i)\Big)&amp;hellip;(5) $$ 由（5）式可得梯度被分解为两项，第一项确保了信息可以直接传播回任意浅层特征，第二项确保了即使权重任意小，层的梯度也不会消失。</description>
    </item>
    
    <item>
      <title>Seminar-20220820-AlexNet, GoogLeNet, VGGNet</title>
      <link>https://meanvery.github.io/post/seminar-20220820/</link>
      <pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220820/</guid>
      <description>感谢高丹阳学姐的讲解！
AlexNet 首次使用GPU进行模型训练 使用ReLU激活函数代替Sigmoid/Tanh 使用规范层(Local Response Normalization, LRN) 使用随机丢弃策略(Dropout) GoogLeNet12 Inception(也称为GoogLeNet)结构的核心思想与贡献：
使用 \(1\times1\) 的卷积来进行升降维 在相同尺寸的感受野种叠加更多的卷积，能提取更丰富的特征。同时在卷积之后都跟着激活函数，多层卷积与激活也有助于组合出更多的非线性特征 降低了计算的复杂度，对输入降维后再做卷积计算量明显减小 在多个尺寸上同时进行卷积后再进行聚合 直观上在多个尺度上同时进行卷积，能提取到不同尺度的特征，特征更丰富也意味着最后分类判断时更加准确 利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度 Hebbin赫布原理，&amp;ldquo;fire together, wire together&amp;rdquo; : 两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种组合，其中一个神经元的兴奋会促进另一个的兴奋 GoogLeNet网络深度深，为了避免梯度消失，网络额外增加了两个辅助的Softmax用于向前传导梯度。
VGGNet3 采用连续的几个 \(3\times3\) 卷积核代替AlexNet中的较大卷积核，即&#34;金字塔方法&#34;。金字塔方法示意图优点 结构简洁，整个网络都使用了相同大小的卷积核尺寸( \(3\times3\) )和最大池化尺寸(\(2\times2\)) 几个小卷积核的组合比一个大卷积核效果更好 验证了加深网络结构可以提升性能 缺点 使用了更多参数，耗费更多计算资源，导致更多的内存占用 https://zhuanlan.zhihu.com/p/32702031&amp;#160;&amp;#x21a9;&amp;#xfe0e;
https://blog.csdn.net/guoyunfei20/article/details/78395500&amp;#160;&amp;#x21a9;&amp;#xfe0e;
https://zhuanlan.zhihu.com/p/41423739&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>An Overview of Computer Vision</title>
      <link>https://meanvery.github.io/post/20220711/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/20220711/</guid>
      <description>Computer Vision1 Image Classification(图像分类)：将图片按内容分到某一类别 Object Detection(物体检测)：检测出图片中的目标对象 Segmentation(图像分割)：将图片按内容分割 Semantic Segmentation(语义分割)：不同物体分成不同的部分 Instance Segmentation(实例分割)：同一物体要分为不同个体 Image Generation(图像生成) 1 Neural Network 1.1 Forward Propogation(前向传播) The input data should be fed in the forward direction only. 神经元通过加权和与激活函数决定是否进一步传递数据。 常见激活函数：Sigmoid, ReLU, Softmax, Hyperbolic Tangent
1.2 Back Propogation(反向传播) It is the practice of fine-tuning the weights of a neural net based on the error rate obtained in the previous epoch.
1.3 Several Loss Function(损失函数) Mean Absolute Error(平均绝对误差) Mean Square Error(均方误差) Hinge Loss(铰链损失) Cross Entropy Loss(交叉熵损失) 1.</description>
    </item>
    
    <item>
      <title>format guide</title>
      <link>https://meanvery.github.io/post/format_rules/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/format_rules/</guid>
      <description>小标题 字体从大到小六个级别，H1最大，H6最小
H1 H2 H3 H4 H5 H6 这里的内容将在黑线 | 之后显示 这里同上
bold
斜体格式
灰色色块显著
引用格式1
表格项1 表格项2 内容1 内容2 内容3 内容4 反引号法黑色背景，通常用于代码块 xxxx&amp;quot;四空格法&amp;quot;黑色背景xxxx大括号法 黑色背景 编号 有序号的编号 第一 第二 第三 无序号（小圆点） 内容 内容 内容 嵌套编号 内容 嵌套1 嵌套2 嵌套3 内容 嵌套1 嵌套2 其他格式 缩写
H下标O
X上标
输入内容
黄色块高亮显示
新起一行
the above quote is excerpted from xxxxxx [article] (https://www.baidu.com) during xxxxxxx,日期&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>first try</title>
      <link>https://meanvery.github.io/post/try/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/try/</guid>
      <description>how to use this</description>
    </item>
    
    <item>
      <title>Markdown Syntax Guide</title>
      <link>https://meanvery.github.io/post/markdown-syntax/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/markdown-syntax/</guid>
      <description>&lt;p&gt;This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rich Content</title>
      <link>https://meanvery.github.io/post/rich-content/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/rich-content/</guid>
      <description>&lt;p&gt;Hugo ships with several &lt;a href=&#34;https://gohugo.io/content-management/shortcodes/#use-hugos-built-in-shortcodes&#34;&gt;Built-in Shortcodes&lt;/a&gt; for rich content, along with a &lt;a href=&#34;https://gohugo.io/about/hugo-and-gdpr/&#34;&gt;Privacy Config&lt;/a&gt; and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Placeholder Text</title>
      <link>https://meanvery.github.io/post/placeholder-text/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/placeholder-text/</guid>
      <description>&lt;p&gt;Lorem est tota propiore conpellat pectoribus de pectora summo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Math Typesetting</title>
      <link>https://meanvery.github.io/post/math-typesetting/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/math-typesetting/</guid>
      <description>&lt;p&gt;Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Emoji Support</title>
      <link>https://meanvery.github.io/post/emoji-support/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/emoji-support/</guid>
      <description>&lt;p&gt;Emoji can be enabled in a Hugo project in a number of ways.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
