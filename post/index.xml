<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Very的计算机学习</title>
    <link>https://meanvery.github.io/post/</link>
    <description>Recent content in Posts on Very的计算机学习</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright © 2008–2019, Steve Francia and the lee.so; all rights reserved.</copyright>
    <lastBuildDate>Mon, 05 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meanvery.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Seminar-20220903-R-CNN, FPN</title>
      <link>https://meanvery.github.io/post/seminar-20220903/</link>
      <pubDate>Mon, 05 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220903/</guid>
      <description>感谢赵永瑞同学的讲解！
R-CNN1 ​	因为研究者结合了区域提名（Region Proposals）和卷积神经网络（CNN），因此将其命名为 R-CNN。
R-CNN 基本流程示意图​	由上图可知，在测试时，首先输入图片，依据选择性搜索（Selective Search）算法，得到大约 2000 个类别无关的区域提名；然后将提名的全部区域的边界，向外扩张 16 个像素，接着无论其大小或者纵横比怎么不同，都缩放到同一尺寸（ \(227 \times 227\) ）；再利用 CNN 提取出特征向量，其中包含了 5 个卷积层和 2 个全连接层，提取到的特征向量维度为 4096；最后通过线性支持向量机对区域进行分类。
​	此外还面临着带标签数据不足，因此大型 CNN 难以训练的问题；在研究者提出的模型中使用了，在大型辅助数据集（ILSVRC）上进行带监督的预训练，然后再在小数据集（PASCAL）上进行参数等微调的方式。结果表明在数据有限时，这是一种相当有效的方式。
​	在 R-CNN 后续研究中，研究人员发现只需要一个简单的边框回归方法，就可以让错误定位显著减少。
FPN2 ​	识别图片中不同尺度的物体一直是计算机视觉中一个重要的任务。
多尺度融合发展示意图​	图片金字塔（Feature Pyramids）为标准化方法提供了基本的思路，如上图中 （a）：将一张图片变换为不同尺寸，然后在每种尺寸上，进行卷积运算特征提取并进行预测。但是这种方式一张图片就要当作多张图片去训练和计算，时间成本太高。
​	改进的方法如上图（b），对一张图片进行卷积操作，然后仅利用多次卷积后得到的深层语义特征进行预测。速度较快，但是没有用到浅层的信息，特征图分辨率也低，不能准确包含物体的位置信息。
​	进一步改进如上图（c），对一张图片进行卷积操作，从每次卷积后的特征图上进行预测，虽然不需要额外的计算，但是单一尺度的语义特征不够丰富。
​	如上图（d），为了融合不同尺度的特征，研究人员提出了 Feature Pyramid Network 即 FPN。
​	在 FPN 中，主要包含了三个过程：自底向上，自顶向下，横向连接。
FPN 示意图自底向上（Bottom-Up Pathway）
将原始图片输入 CNN 进行特征提取，经过卷积层时，因为卷积核和步长等设置，有的输出图与输入图一致（这些卷积层归为一个 stage ），有的输出图缩小为原来的 \(1/2\) （划分到下一个 stage ）。将每个 stage 中的最后一层输出的特征抽取出来（最后一层经过了最多的计算，语义最丰富），由于第一个 stage 的输出特征图占用内存过大，因此舍弃。最后不同 stage 的输出图尺寸其实与原图尺寸依次保持着 4，8，16，32 倍的关系。</description>
    </item>
    
    <item>
      <title>Seminar-20220831-ShuffleNet, EfficientNet</title>
      <link>https://meanvery.github.io/post/seminar-20220831/</link>
      <pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220831/</guid>
      <description>感谢周羿旭师兄的讲解！
ShuffleNet1 2 3 4 ​	研究人员注意到，由于计算代价颇大的密集 \(1 \times 1\) 卷积，Xception 和 ResNeXt 等最先进的架构在规模很小的网络中效率较低。于是使用了逐点组卷积来降低 \(1 \times 1\) 卷积的计算复杂度。 同时为了克服组卷积带来的副作用（通道间信息交流问题），研究人员提出了一种新颖的通道混洗操作（shuffle）来帮助信息在特征通道之间流动。 ​	基于这两种技术，他们构建了一个称为 ShuffleNet 的高效架构。 与当初流行的结构相比，对于给定的计算复杂度预算，ShuffleNet 允许更多的特征图通道编码更多信息，同时使得规模非常小的网络的性能也能达到较好的水平。
​	在规模较小的网络中，计算代价昂贵的点卷积（pointwise convolution）导致了，如果想要保持较低的计算复杂度，就必须减少通道数量，然而这会使得准确率显著下降。为了解决这个问题，就只有进行稀疏连接（sparse connection），每个卷积操作仅作用于相关的输入通道组，即分组卷积，但是这又会阻碍通道间的信息交流，并因此弱化特征表达能力。
​	所以在稀疏连接的基础上，还需要让分组卷积获得其他组的数据。由此想到了 channel shuffle 操作，在每个通道的基础上，再进行分组，得到通道的子序列，将这些子序列重新有规则地组合，形成下一层的输入。
channel shuffle 示意图ShuffleNet Unit的设计EfficientNet5 6 7 8 ​	扩张卷积网络被广泛用于追求更高准确度，比如使用更多的层使得 ResNet-18 变为 ResNet-200。但是扩张卷积网络的过程其实还没有被人们琢磨清楚，现在也有许多方式来完成扩张，比如增加深度，宽度，分辨率。尽管人们可以随意选择维度对网络进行个性化的扩张，但是随意地调整后，需要繁复的参数调节，并且效果（准确率，效率等）并不一定优良。
​	因此研究人员重新学习反思了卷积网络扩大规模的过程，并提出了关键性的问题——是否有一个标准化的方法去扩张网络，使之总能得到更好的准确率和效率。在实验过程中，研究人员发现，需要去平衡网络的深度，宽度和分辨率。但是出乎意料的是，不需要非常复杂的数学函数关系，这种平衡可以通过简单地以恒定比例缩放其中每一个维度来实现。
​	在文章中，研究人员提出了复合缩放算法（Compound Scaling Method），使用了复合因子 \(\phi\) 来规范地缩放宽度，深度和分辨率： $$ depth:d=\alpha^\phi \ width:w=\beta^\phi \ resolution:r=\gamma^\phi \ s.t. \space \alpha \cdot \beta^2 \cdot \gamma^2 \approx 1 \ \space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\alpha \geq 1,\beta \geq1,\gamma \geq1 $$ ​	其中 \(\phi\) 是人为确定的因子，根据计算资源的变化进行不同的调整； \(\alpha,\beta,\gamma\) 为常数，可以根据小规模的网格搜索求解。</description>
    </item>
    
    <item>
      <title>Seminar-20220827-SENet, MobileNet</title>
      <link>https://meanvery.github.io/post/seminar-20220827/</link>
      <pubDate>Sat, 27 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220827/</guid>
      <description>感谢张若淇师兄的讲解！
SENet1 2 3 ​	在之前的研究中，人们重点关注空间维度上特征的联系与交互，但是 SENet 研究了网络设计的不同方面——通道（channel）之间的关系。SENet 设计了一个新的结构单元，称之为 Squeeze-and-Excitation（SE）块，它是为了建立特征图通道之间的关系，并以此来提升特征表示的效果。
A Squeeze-and-Excitation block​	其中， \(X\) 是初始的特征图，高度宽度通道数分别为 \(H&#39;\) ， \(W&#39;\) ， \(C&#39;\) 。
​	\(F_{tr}\) 是传统的卷积操作将 \(X\) 变换为 \(U\) ，高度宽度通道数分别为 \(H\) ， \(W\) ， \(C\) 。
​	然后使 \(U\) 经过 Squeeze 操作即 \(F_{sq}\) ，变换成 \(1 \times 1 \times C\) 的通道描述向量 \(z\) 。实际上是用全局平均池化，将每一通道上原本为 \(H \times W\) 的二维矩阵通过求平均的方式，化为一个实数，这个实数其实一定程度上包含了每一通道上的全局视野。同时，化成 \(1 \times 1 \times C\) 也避免了高度和宽度（也即空间特征）带来的影响，从而突出了通道的作用。
​	再让 \(1 \times 1 \times C\) 的通道描述向量 \(z\) 经过 Excitation 变换，实际上经过了两个全连接层。</description>
    </item>
    
    <item>
      <title>Seminar-20220824-ResNet, DenseNet</title>
      <link>https://meanvery.github.io/post/seminar-20220824/</link>
      <pubDate>Wed, 24 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220824/</guid>
      <description>感谢陈露元同学的讲解！
ResNet1 2 ​	从之前已有的研究中可以看出，似乎神经网络的深度越深，学习效果就越好。但这个结论其实并不可靠：一个问题是，随着深度的增加而出现的梯度消失或梯度爆炸现象，影响最后的收敛，不过这种收敛问题可以通过正则化（regularization）得到部分解决；另一个问题是，网络即使收敛，在深度增加时，正确率却无法进一步提高甚至还会下降，称为网络的退化（degradation）问题。
​	考虑一个极端的情形，如果增加的所有层都是前一层的直接复制，那么深层网络的训练误差应当和浅层网络相等，因此网络退化的根本原因是优化的问题，不是所有的系统都很容易优化。
​	为了解决优化的难题，提出了残差网络，不让网络直接拟合原先的映射，而是拟合残差映射。
Residual learning: a building block​	上图为残差网络中的一个模块，identity mapping 为恒等映射。由上图，残差网络可以理解为在前向网络中增加了一些快捷连接（shortcut connections），这些连接会跳过某些层，直接将原始数据传到之后的层。新增的快捷连接也不会增加模型的参数和复杂度，整个模型依然可以使用端到端的方法进行训练（比如随机梯度下降法）。
不同层数的ResNet架构总结 ​	ResNet 将部分原始输入信息不经过矩阵乘法和非线性变换，直接传输到下一层，快捷连接如同在深层网络中建立起了信息的捷径。通过改变学习目标，残差网络不再学习完整的输出而是学习残差，不仅降低了学习的难度，而且解决了传统卷积层或者全连接层在信息传递时存在的丢失和损耗问题——直接将信息从输入绕道传到输出，一定程度上保护了信息的完整性。
ResNet.version23 4 对resnet的改良​	实验表明，保持一个单纯的信息传送通道（如上图中 b 所示）对降低优化的难度有帮助。
残差网络的分析
原始版本的残差模块，利用公式描述如下： $$ y_l = h(x_l)+F(x_l,W_l)&amp;hellip;(1) $$
$$ x_{l+1} = f(y_l)&amp;hellip;(2) $$
其中，\(x_l\)为第\(l\)层残差模块的输入特征，\(W_l\)是权重系数，\(F\)是残差函数，\(f\)是ReLU函数，\(h\)是恒等映射，即\(h({x_l}) = x_l\)。
如果我们设\(f\)也是恒等映射，即\(x_{l+1} = y_l\)，则可将（2）式代入（1）式，可得： $$ x_{l+1} = x_l + F(x_l,W_l)&amp;hellip;(3) $$ 类似的可推得： $$ x_L= x_l + \displaystyle\sum_{i=l}^{L-1}F(x_i,W_i)&amp;hellip;(4) $$ 由（4）式可得任意深层特征都可以用浅层特征加上残差项来表达，而对原始 ResNet，深层特征实际是各项相乘。
对损失函数求导可得： $$ \dfrac{\partial \varepsilon}{\partial x_l}=\dfrac{\partial \varepsilon}{\partial x_L}\dfrac{\partial x_L}{\partial x_l}=\dfrac{\partial \varepsilon}{\partial x_L}\Big(1+\dfrac{\partial}{\partial x_l}\displaystyle\sum_{i=l}^{L-1}F(x_i,W_i)\Big)&amp;hellip;(5) $$ 由（5）式可得梯度被分解为两项，第一项确保了信息可以直接传播回任意浅层特征，第二项确保了即使权重任意小，层的梯度也不会消失。</description>
    </item>
    
    <item>
      <title>Seminar-20220820-AlexNet, GoogLeNet, VGGNet</title>
      <link>https://meanvery.github.io/post/seminar-20220820/</link>
      <pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/seminar-20220820/</guid>
      <description>感谢高丹阳学姐的讲解！
AlexNet 首次使用GPU进行模型训练 使用ReLU激活函数代替Sigmoid/Tanh 使用规范层(Local Response Normalization, LRN) 使用随机丢弃策略(Dropout) GoogLeNet12 Inception(也称为GoogLeNet)结构的核心思想与贡献：
使用 \(1\times1\) 的卷积来进行升降维 在相同尺寸的感受野种叠加更多的卷积，能提取更丰富的特征。同时在卷积之后都跟着激活函数，多层卷积与激活也有助于组合出更多的非线性特征 降低了计算的复杂度，对输入降维后再做卷积计算量明显减小 在多个尺寸上同时进行卷积后再进行聚合 直观上在多个尺度上同时进行卷积，能提取到不同尺度的特征，特征更丰富也意味着最后分类判断时更加准确 利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度 Hebbin赫布原理，&amp;ldquo;fire together, wire together&amp;rdquo; : 两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种组合，其中一个神经元的兴奋会促进另一个的兴奋 GoogLeNet网络深度深，为了避免梯度消失，网络额外增加了两个辅助的Softmax用于向前传导梯度。
VGGNet3 采用连续的几个 \(3\times3\) 卷积核代替AlexNet中的较大卷积核，即&#34;金字塔方法&#34;。金字塔方法示意图优点 结构简洁，整个网络都使用了相同大小的卷积核尺寸( \(3\times3\) )和最大池化尺寸(\(2\times2\)) 几个小卷积核的组合比一个大卷积核效果更好 验证了加深网络结构可以提升性能 缺点 使用了更多参数，耗费更多计算资源，导致更多的内存占用 https://zhuanlan.zhihu.com/p/32702031&amp;#160;&amp;#x21a9;&amp;#xfe0e;
https://blog.csdn.net/guoyunfei20/article/details/78395500&amp;#160;&amp;#x21a9;&amp;#xfe0e;
https://zhuanlan.zhihu.com/p/41423739&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>An Overview of Computer Vision</title>
      <link>https://meanvery.github.io/post/20220711/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/20220711/</guid>
      <description>Computer Vision1 Image Classification(图像分类)：将图片按内容分到某一类别 Object Detection(物体检测)：检测出图片中的目标对象 Segmentation(图像分割)：将图片按内容分割 Semantic Segmentation(语义分割)：不同物体分成不同的部分 Instance Segmentation(实例分割)：同一物体要分为不同个体 Image Generation(图像生成) 1 Neural Network 1.1 Forward Propogation(前向传播) The input data should be fed in the forward direction only. 神经元通过加权和与激活函数决定是否进一步传递数据。 常见激活函数：Sigmoid, ReLU, Softmax, Hyperbolic Tangent
1.2 Back Propogation(反向传播) It is the practice of fine-tuning the weights of a neural net based on the error rate obtained in the previous epoch.
1.3 Several Loss Function(损失函数) Mean Absolute Error(平均绝对误差) Mean Square Error(均方误差) Hinge Loss(铰链损失) Cross Entropy Loss(交叉熵损失) 1.</description>
    </item>
    
    <item>
      <title>format guide</title>
      <link>https://meanvery.github.io/post/format_rules/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/format_rules/</guid>
      <description>小标题 字体从大到小六个级别，H1最大，H6最小
H1 H2 H3 H4 H5 H6 这里的内容将在黑线 | 之后显示 这里同上
bold
斜体格式
灰色色块显著
引用格式1
表格项1 表格项2 内容1 内容2 内容3 内容4 反引号法黑色背景，通常用于代码块 xxxx&amp;quot;四空格法&amp;quot;黑色背景xxxx大括号法 黑色背景 编号 有序号的编号 第一 第二 第三 无序号（小圆点） 内容 内容 内容 嵌套编号 内容 嵌套1 嵌套2 嵌套3 内容 嵌套1 嵌套2 其他格式 缩写
H下标O
X上标
输入内容
黄色块高亮显示
新起一行
the above quote is excerpted from xxxxxx [article] (https://www.baidu.com) during xxxxxxx,日期&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>first try</title>
      <link>https://meanvery.github.io/post/try/</link>
      <pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/try/</guid>
      <description>how to use this</description>
    </item>
    
    <item>
      <title>Markdown Syntax Guide</title>
      <link>https://meanvery.github.io/post/markdown-syntax/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/markdown-syntax/</guid>
      <description>&lt;p&gt;This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rich Content</title>
      <link>https://meanvery.github.io/post/rich-content/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/rich-content/</guid>
      <description>&lt;p&gt;Hugo ships with several &lt;a href=&#34;https://gohugo.io/content-management/shortcodes/#use-hugos-built-in-shortcodes&#34;&gt;Built-in Shortcodes&lt;/a&gt; for rich content, along with a &lt;a href=&#34;https://gohugo.io/about/hugo-and-gdpr/&#34;&gt;Privacy Config&lt;/a&gt; and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Placeholder Text</title>
      <link>https://meanvery.github.io/post/placeholder-text/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/placeholder-text/</guid>
      <description>&lt;p&gt;Lorem est tota propiore conpellat pectoribus de pectora summo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Math Typesetting</title>
      <link>https://meanvery.github.io/post/math-typesetting/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/math-typesetting/</guid>
      <description>&lt;p&gt;Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Emoji Support</title>
      <link>https://meanvery.github.io/post/emoji-support/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/emoji-support/</guid>
      <description>&lt;p&gt;Emoji can be enabled in a Hugo project in a number of ways.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
