<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>计算机视觉 on Very的计算机学习</title>
    <link>https://meanvery.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/</link>
    <description>Recent content in 计算机视觉 on Very的计算机学习</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright © 2008–2019, Steve Francia and the lee.so; all rights reserved.</copyright>
    <lastBuildDate>Mon, 11 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://meanvery.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>An Overview of Computer Vision</title>
      <link>https://meanvery.github.io/post/20220711/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://meanvery.github.io/post/20220711/</guid>
      <description>Computer Vision1 Image Classification(图像分类)：将图片按内容分到某一类别 Object Detection(物体检测)：检测出图片中的目标对象 Segmentation(图像分割)：将图片按内容分割 Semantic Segmentation(语义分割)：不同物体分成不同的部分 Instance Segmentation(实例分割)：同一物体要分为不同个体 Image Generation(图像生成) 1 Neural Network 1.1 Forward Propogation(前向传播) The input data should be fed in the forward direction only. 神经元通过加权和与激活函数决定是否进一步传递数据。
常见激活函数：Sigmoid, ReLU, Softmax, Hyperbolic Tangent
1.2 Back Propogation(反向传播) It is the practice of fine-tuning the weights of a neural net based on the error rate obtained in the previous epoch.
1.3 Several Loss Function(损失函数) Mean Absolute Error(平均绝对误差) Mean Square Error(均方误差) Hinge Loss(铰链损失) Cross Entropy Loss(交叉熵损失) 1.</description>
    </item>
    
  </channel>
</rss>
